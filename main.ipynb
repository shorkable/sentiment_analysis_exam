{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NB\n",
    "\n",
    "### Produkt\n",
    "Based on news headlines from a day, we want to develop a model that is able to predict whether the closing price will rise or fall.\n",
    "\n",
    "Antagelse: Title udkom inden Closing, så Title påvirker dagens CP.\n",
    "\n",
    "Step 1: Define sentiment in headlines\n",
    "- Use a model from huggingface\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library imports\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>CP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPMorgan Predicts 2008 Will Be \"Nothing But Net\"</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dow Tallies Biggest First-session-of-year Poin...</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008 predictions for the S&amp;P 500</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date       CP\n",
       "0   JPMorgan Predicts 2008 Will Be \"Nothing But Net\"  2008-01-02  1447.16\n",
       "1  Dow Tallies Biggest First-session-of-year Poin...  2008-01-02  1447.16\n",
       "2                   2008 predictions for the S&P 500  2008-01-02  1447.16"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing and investigating the data\n",
    "data = pd.read_csv('data.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why's the Dow Down While the S&P and Nasdaq Hit Record Highs?\n",
      "negative\n",
      "Stock Market Week in Review: Wall Street Was Not Bullish Enough on 2021\n",
      "negative\n",
      "Researchers use Wall Street Journal articles to predict stock returns\n",
      "neutral\n",
      "Stock Market News for Nov 19, 2021\n",
      "neutral\n",
      "The 30 Best Stocks of the Past 30 Years\n",
      "neutral\n",
      "Inflation drives investors to US stocks\n",
      "neutral\n",
      "Return to Normal Puts S&P 500 at 5000 in June, UBS's Lovell Says\n",
      "negative\n",
      "COVID fears weigh on Dow, S&P 500; Nasdaq hits record high\n",
      "negative\n",
      "Is S&P 500 going to burst?. Let’s see if the unstoppable rising of… | by Gianluca Malato\n",
      "neutral\n",
      "Is the UMAX ETF a solid dividend income idea?\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "#Use finbert model, found on HuggingFace\n",
    "classifier = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "results = []\n",
    "\n",
    "last_price = data.iloc[0]['CP'] #This variable is used for calculating the price difference from day to day\n",
    "previous_date = data.iloc[0]['Date']\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    \"\"\"\n",
    "    This for loop extracts the sentiment from the headlines\n",
    "    \n",
    "    Each headline is then awarded a sentiment score: Positive (+) for positive sentiment, 0 for neutral and Negative (-) for negative sentiment\n",
    "    The score in this reflects how sure the model is. If there are more than one headline per day, the scores are aggregated to mean in a later step\n",
    "    \"\"\"\n",
    "    if index < 2000:\n",
    "        output = classifier(row['Title'])\n",
    "\n",
    "        label = output[0]['label']\n",
    "        score = output[0]['score']\n",
    "\n",
    "        #Assign sentiment score (- if negative, + if positive)\n",
    "        if label == 'negative':\n",
    "            sentiment_score = -score\n",
    "        elif label == 'neutral':\n",
    "            sentiment_score = 0\n",
    "        elif label == 'positive':\n",
    "            sentiment_score = score      \n",
    "\n",
    "        price_difference = row['CP'] - last_price\n",
    "\n",
    "        price_difference_percentage = ((row['CP'] - last_price) / last_price) * 100\n",
    "\n",
    "        results.append([row['Date'], sentiment_score, price_difference, price_difference_percentage])\n",
    "\n",
    "        #If the next Date is different, change the last_price variable\n",
    "        if row['Date'] != data.iloc[index +1]['Date']:\n",
    "            last_price = row['CP']\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"Date\", \"Score\", \"Total price difference\", \"Percentage price difference\"])\n",
    "\n",
    "#Aggregate to a per-day basis\n",
    "grouped_df = df.groupby(['Date'], as_index=False).mean() #Use mean of scores. This way, we represent the full sentiment in the market\n",
    "grouped_df.to_csv('aggregated_per_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentimentF24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
