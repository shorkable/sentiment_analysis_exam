{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NB\n",
    "\n",
    "### Produkt\n",
    "Based on news headlines from a day, we want to develop a model that is able to predict whether the closing price will rise or fall.\n",
    "\n",
    "Antagelse: Title udkom inden Closing, så Title påvirker dagens CP.\n",
    "\n",
    "Step 1: Define sentiment in headlines\n",
    "- Use a model from huggingface\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>CP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPMorgan Predicts 2008 Will Be \"Nothing But Net\"</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dow Tallies Biggest First-session-of-year Poin...</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008 predictions for the S&amp;P 500</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date       CP\n",
       "0   JPMorgan Predicts 2008 Will Be \"Nothing But Net\"  2008-01-02  1447.16\n",
       "1  Dow Tallies Biggest First-session-of-year Poin...  2008-01-02  1447.16\n",
       "2                   2008 predictions for the S&P 500  2008-01-02  1447.16"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing and investigating the data\n",
    "data = pd.read_csv('data.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify sentiment\n",
    "The following code uses a transformer model to analyse sentiment of the headlines into either positive, neutral, or negative. Each sentiment is given a score based on how sure the model is, and these scores are later averaged on a per-day basis to find average sentiment on that day. Also, the price difference to the day before is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Data for the first 10 days: -----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total price difference</th>\n",
       "      <th>Percentage price difference</th>\n",
       "      <th>Price increase</th>\n",
       "      <th>Price decrease</th>\n",
       "      <th>Positive sentiment</th>\n",
       "      <th>Negative sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>-0.522108</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>0.861627</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>0.586567</td>\n",
       "      <td>-30.98</td>\n",
       "      <td>-2.140745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-09</td>\n",
       "      <td>-0.421696</td>\n",
       "      <td>-7.05</td>\n",
       "      <td>-0.497818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-10</td>\n",
       "      <td>0.542341</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.794817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-01-22</td>\n",
       "      <td>-0.602433</td>\n",
       "      <td>-109.83</td>\n",
       "      <td>-7.732710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-01-29</td>\n",
       "      <td>-0.766623</td>\n",
       "      <td>51.80</td>\n",
       "      <td>3.952690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-01-30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.49</td>\n",
       "      <td>-0.476400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-02-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.61</td>\n",
       "      <td>2.921501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-02-05</td>\n",
       "      <td>-0.308031</td>\n",
       "      <td>-58.78</td>\n",
       "      <td>-4.212352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Score  Total price difference  Percentage price difference  \\\n",
       "0  2008-01-02 -0.522108                    0.00                     0.000000   \n",
       "1  2008-01-03  0.861627                    0.00                     0.000000   \n",
       "2  2008-01-07  0.586567                  -30.98                    -2.140745   \n",
       "3  2008-01-09 -0.421696                   -7.05                    -0.497818   \n",
       "4  2008-01-10  0.542341                   11.20                     0.794817   \n",
       "5  2008-01-22 -0.602433                 -109.83                    -7.732710   \n",
       "6  2008-01-29 -0.766623                   51.80                     3.952690   \n",
       "7  2008-01-30  0.000000                   -6.49                    -0.476400   \n",
       "8  2008-02-01  0.000000                   39.61                     2.921501   \n",
       "9  2008-02-05 -0.308031                  -58.78                    -4.212352   \n",
       "\n",
       "   Price increase  Price decrease  Positive sentiment  Negative sentiment  \n",
       "0             0.0             0.0                   0                   1  \n",
       "1             0.0             0.0                   1                   0  \n",
       "2             0.0             1.0                   1                   0  \n",
       "3             0.0             1.0                   0                   1  \n",
       "4             1.0             0.0                   1                   0  \n",
       "5             0.0             1.0                   0                   1  \n",
       "6             1.0             0.0                   0                   1  \n",
       "7             0.0             1.0                   0                   0  \n",
       "8             1.0             0.0                   0                   0  \n",
       "9             0.0             1.0                   0                   1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use finbert model, found on HuggingFace\n",
    "classifier = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "results = []\n",
    "\n",
    "last_price = data.iloc[0]['CP'] #This variable is used for calculating the price difference from day to day\n",
    "previous_date = data.iloc[0]['Date']\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    \"\"\"\n",
    "    This for loop extracts the sentiment from the headlines\n",
    "    \n",
    "    Each headline is then awarded a sentiment score: Positive (+) for positive sentiment, 0 for neutral and Negative (-) for negative sentiment\n",
    "    The score in this reflects how sure the model is. If there are more than one headline per day, the scores are aggregated to mean in a later step\n",
    "    \"\"\"\n",
    "    output = classifier(row['Title'])\n",
    "\n",
    "    label = output[0]['label']\n",
    "    score = output[0]['score']\n",
    "\n",
    "    #Assign sentiment score (- if negative, + if positive)\n",
    "    if label == 'negative':\n",
    "        sentiment_score = -score\n",
    "    elif label == 'neutral':\n",
    "        sentiment_score = 0\n",
    "    elif label == 'positive':\n",
    "        sentiment_score = score      \n",
    "\n",
    "    price_difference = row['CP'] - last_price\n",
    "\n",
    "    if price_difference > 0:\n",
    "        price_increase = 1\n",
    "        price_decrease = 0\n",
    "    elif price_difference < 0:\n",
    "        price_increase = 0\n",
    "        price_decrease = 1\n",
    "    else:\n",
    "        price_increase = 0\n",
    "        price_decrease = 0\n",
    "    \n",
    "    price_difference_percentage = ((row['CP'] - last_price) / last_price) * 100\n",
    "\n",
    "    #Return score as well as price-difference to previous day both in total and as a percentage\n",
    "    results.append([row['Date'], sentiment_score, price_difference, price_difference_percentage, price_increase, price_decrease])\n",
    "\n",
    "    #If the next Date is different, change the last_price variable\n",
    "    try:\n",
    "        if row['Date'] != data.iloc[index +1]['Date']:\n",
    "            last_price = row['CP']\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"Date\", \"Score\", \"Total price difference\", \"Percentage price difference\", \"Price increase\", \"Price decrease\"])\n",
    "\n",
    "#Aggregate to a per-day basis\n",
    "grouped_df = df.groupby(['Date'], as_index=False).mean() #Use mean of scores. This way, we represent the overall sentiment in the market on the given day\n",
    "grouped_df.to_csv('aggregated_per_day.csv')\n",
    "grouped_df['Positive sentiment'] = np.where(grouped_df['Score'] > 0, 1, 0)\n",
    "grouped_df['Negative sentiment'] = np.where(grouped_df['Score'] < 0, 1, 0)\n",
    "\n",
    "print(\"----- Data for the first 10 days: -----\")\n",
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prior probabilities ---\n",
      "P(Price Increase): 0.54\n",
      "P(Price Decrease): 0.46\n",
      "P(Positive sentiment): 0.25\n",
      "P(Negative sentiment): 0.44\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Prior probabilities ---\")\n",
    "print(f\"P(Price Increase): {round(grouped_df['Price increase'].sum() / len(grouped_df),2)}\")\n",
    "print(f\"P(Price Decrease): {round(grouped_df['Price decrease'].sum() / len(grouped_df),2)}\")\n",
    "print(f\"P(Positive sentiment): {round(grouped_df['Positive sentiment'].sum() / len(grouped_df),2)}\")\n",
    "print(f\"P(Negative sentiment): {round(grouped_df['Negative sentiment'].sum() / len(grouped_df),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above prior probabilities suggest a slightly imbalanced dataset leaning towards price increases. If we invest randomly, 54% of the days we will have a price increase (not considering broker fees etc.). Throughout the rest of the project, we will investigate, if this probability can be increased using sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of increase / decrease\n",
    "The later models will attempt to predict the price increase / decrease with regression. As a baseline model, the authors decided to attempt a classification prediction of whether the given headlines' sentiment will trigger an increase / decrease compared to the previous day. This classification will be performed with the Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation ---\n",
      "Shuffle = True\n",
      "\n",
      "-- Predictions based on categorical values --\n",
      "For prediction of price increases, the model has an accuracy of: 0.5883\n",
      "For prediction of price decrease, the model has an accuracy of: 0.5897\n",
      "\n",
      "-- Predictions based on numerical (continuous) values --\n",
      "For prediction of price increase, the model has an accuracy of: 0.5883\n",
      "For prediction of price decrease, the model has an accuracy of: 0.5912\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Shuffle = False\n",
      "\n",
      "-- Predictions based on categorical values --\n",
      "For prediction of price increases, the model has an accuracy of: 0.6567\n",
      "For prediction of price decrease, the model has an accuracy of: 0.6567\n",
      "\n",
      "-- Predictions based on numerical (continuous) values --\n",
      "For prediction of price increase, the model has an accuracy of: 0.5983\n",
      "For prediction of price decrease, the model has an accuracy of: 0.5997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Try with and without shuffling the data\n",
    "for shuffle in [True, False]:\n",
    "    ### -- Try modelling for price increase based on categorical sentiment -- ###\n",
    "    #Get train and test data from the dataset\n",
    "    X, y = grouped_df[['Positive sentiment', 'Negative sentiment']], grouped_df['Price increase']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    increase_accuracy_categorical = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    ### -- Modelling for price decrease on categorical sentiment -- ###\n",
    "    #Get train and test data from the dataset\n",
    "    X, y = grouped_df[['Positive sentiment', 'Negative sentiment']], grouped_df['Price decrease']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    decrease_accuracy_categorical = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    ### -- Modelling for price decrease on numerical (continuous) sentiment -- ###\n",
    "    #Get train and test data from the dataset\n",
    "    X, y = grouped_df[['Score']], grouped_df['Price decrease']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    decrease_accuracy_numerical = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    ### -- Modelling for price increase on numerical (continuous) sentiment -- ###\n",
    "    #Get train and test data from the dataset\n",
    "    X, y = grouped_df[['Score']], grouped_df['Price increase']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    increase_accuracy_numerical = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"--- Model Evaluation ---\")\n",
    "    print(f\"Shuffle = {shuffle}\")\n",
    "    print(\"\\n-- Predictions based on categorical values --\")\n",
    "    print(f\"For prediction of price increases, the model has an accuracy of: {increase_accuracy_categorical:.4f}\")\n",
    "    print(f\"For prediction of price decrease, the model has an accuracy of: {decrease_accuracy_categorical:.4f}\")\n",
    "\n",
    "    print(\"\\n-- Predictions based on numerical (continuous) values --\")\n",
    "    print(f\"For prediction of price increase, the model has an accuracy of: {increase_accuracy_numerical:.4f}\")\n",
    "    print(f\"For prediction of price decrease, the model has an accuracy of: {decrease_accuracy_numerical:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We used the Naïve Bayes classifier to try to predict price increases / decreases based on categorical as well as numerical predictors. As the accuracy suggests, this is a slight improvement over the prior probabilities. Especially when the test data is ordered chronologically, a categorical sentiment seems to be able to predict a price increase and decrease quite well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentimentF24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
