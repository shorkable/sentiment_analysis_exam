{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's missing\n",
    "Til næste gang, mandag kl 13 på uni:\n",
    "\n",
    "Jasi:\n",
    "- Estatter billeder af graferne til dem, der indeholder alt data\n",
    "- Sætter et framework op i teksten\n",
    "\n",
    "Rasmus:\n",
    "- Tilføjer Naive Bayes tekst / resultater i \"Jasmin\"\n",
    "- - Tænkt som en test / baseline men klarede sig faktisk okay :)\n",
    "- Random Forest til Classification og til regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>CP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPMorgan Predicts 2008 Will Be \"Nothing But Net\"</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dow Tallies Biggest First-session-of-year Poin...</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008 predictions for the S&amp;P 500</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>1447.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date       CP\n",
       "0   JPMorgan Predicts 2008 Will Be \"Nothing But Net\"  2008-01-02  1447.16\n",
       "1  Dow Tallies Biggest First-session-of-year Poin...  2008-01-02  1447.16\n",
       "2                   2008 predictions for the S&P 500  2008-01-02  1447.16"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing and investigating the data\n",
    "data = pd.read_csv('data.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify sentiment\n",
    "The following code uses a transformer model to analyse sentiment of the headlines into either positive, neutral, or negative. Each sentiment is given a score based on how sure the model is, and these scores are later averaged on a per-day basis to find average sentiment on that day. Also, the price difference to the day before is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Data for the first 10 days: -----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total price difference</th>\n",
       "      <th>Percentage price difference</th>\n",
       "      <th>Price increase</th>\n",
       "      <th>Price decrease</th>\n",
       "      <th>Positive sentiment</th>\n",
       "      <th>Negative sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>-0.522108</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>0.861627</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>0.586567</td>\n",
       "      <td>-30.98</td>\n",
       "      <td>-2.140745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-09</td>\n",
       "      <td>-0.421696</td>\n",
       "      <td>-7.05</td>\n",
       "      <td>-0.497818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-10</td>\n",
       "      <td>0.542341</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.794817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-01-22</td>\n",
       "      <td>-0.602433</td>\n",
       "      <td>-109.83</td>\n",
       "      <td>-7.732710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-01-29</td>\n",
       "      <td>-0.766623</td>\n",
       "      <td>51.80</td>\n",
       "      <td>3.952690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-01-30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.49</td>\n",
       "      <td>-0.476400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-02-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.61</td>\n",
       "      <td>2.921501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-02-05</td>\n",
       "      <td>-0.308031</td>\n",
       "      <td>-58.78</td>\n",
       "      <td>-4.212352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Score  Total price difference  Percentage price difference  \\\n",
       "0  2008-01-02 -0.522108                    0.00                     0.000000   \n",
       "1  2008-01-03  0.861627                    0.00                     0.000000   \n",
       "2  2008-01-07  0.586567                  -30.98                    -2.140745   \n",
       "3  2008-01-09 -0.421696                   -7.05                    -0.497818   \n",
       "4  2008-01-10  0.542341                   11.20                     0.794817   \n",
       "5  2008-01-22 -0.602433                 -109.83                    -7.732710   \n",
       "6  2008-01-29 -0.766623                   51.80                     3.952690   \n",
       "7  2008-01-30  0.000000                   -6.49                    -0.476400   \n",
       "8  2008-02-01  0.000000                   39.61                     2.921501   \n",
       "9  2008-02-05 -0.308031                  -58.78                    -4.212352   \n",
       "\n",
       "   Price increase  Price decrease  Positive sentiment  Negative sentiment  \n",
       "0             0.0             0.0                   0                   1  \n",
       "1             0.0             0.0                   1                   0  \n",
       "2             0.0             1.0                   1                   0  \n",
       "3             0.0             1.0                   0                   1  \n",
       "4             1.0             0.0                   1                   0  \n",
       "5             0.0             1.0                   0                   1  \n",
       "6             1.0             0.0                   0                   1  \n",
       "7             0.0             1.0                   0                   0  \n",
       "8             1.0             0.0                   0                   0  \n",
       "9             0.0             1.0                   0                   1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use finbert model, found on HuggingFace\n",
    "classifier = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "results = []\n",
    "\n",
    "last_price = data.iloc[0]['CP'] #This variable is used for calculating the price difference from day to day\n",
    "previous_date = data.iloc[0]['Date']\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    \"\"\"\n",
    "    This for loop extracts the sentiment from the headlines\n",
    "    \n",
    "    Each headline is then awarded a sentiment score: Positive (+) for positive sentiment, 0 for neutral and Negative (-) for negative sentiment\n",
    "    The score in this reflects how sure the model is. If there are more than one headline per day, the scores are aggregated to mean in a later step\n",
    "    \"\"\"\n",
    "    output = classifier(row['Title'])\n",
    "\n",
    "    label = output[0]['label']\n",
    "    score = output[0]['score']\n",
    "\n",
    "    #Assign sentiment score (- if negative, + if positive)\n",
    "    if label == 'negative':\n",
    "        sentiment_score = -score\n",
    "    elif label == 'neutral':\n",
    "        sentiment_score = 0\n",
    "    elif label == 'positive':\n",
    "        sentiment_score = score      \n",
    "\n",
    "    price_difference = row['CP'] - last_price\n",
    "\n",
    "    if price_difference > 0:\n",
    "        price_increase = 1\n",
    "        price_decrease = 0\n",
    "    elif price_difference < 0:\n",
    "        price_increase = 0\n",
    "        price_decrease = 1\n",
    "    else:\n",
    "        price_increase = 0\n",
    "        price_decrease = 0\n",
    "    \n",
    "    price_difference_percentage = ((row['CP'] - last_price) / last_price) * 100\n",
    "\n",
    "    #Return score as well as price-difference to previous day both in total and as a percentage\n",
    "    results.append([row['Date'], sentiment_score, price_difference, price_difference_percentage, price_increase, price_decrease])\n",
    "\n",
    "    #If the next Date is different, change the last_price variable\n",
    "    try:\n",
    "        if row['Date'] != data.iloc[index +1]['Date']:\n",
    "            last_price = row['CP']\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"Date\", \"Score\", \"Total price difference\", \"Percentage price difference\", \"Price increase\", \"Price decrease\"])\n",
    "\n",
    "#Aggregate to a per-day basis\n",
    "grouped_df = df.groupby(['Date'], as_index=False).mean() #Use mean of scores. This way, we represent the overall sentiment in the market on the given day\n",
    "grouped_df.to_csv('aggregated_per_day.csv')\n",
    "grouped_df['Positive sentiment'] = np.where(grouped_df['Score'] > 0, 1, 0)\n",
    "grouped_df['Negative sentiment'] = np.where(grouped_df['Score'] < 0, 1, 0)\n",
    "\n",
    "print(\"----- Data for the first 10 days: -----\")\n",
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prior probabilities ---\n",
      "P(Price Increase): 0.54\n",
      "P(Price Decrease): 0.46\n",
      "P(Positive sentiment): 0.25\n",
      "P(Negative sentiment): 0.44\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Prior probabilities ---\")\n",
    "print(f\"P(Price Increase): {round(grouped_df['Price increase'].sum() / len(grouped_df),2)}\")\n",
    "print(f\"P(Price Decrease): {round(grouped_df['Price decrease'].sum() / len(grouped_df),2)}\")\n",
    "print(f\"P(Positive sentiment): {round(grouped_df['Positive sentiment'].sum() / len(grouped_df),2)}\")\n",
    "print(f\"P(Negative sentiment): {round(grouped_df['Negative sentiment'].sum() / len(grouped_df),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above prior probabilities suggest a slightly imbalanced dataset leaning towards price increases. If we invest randomly, 54% of the days we will have a price increase (not considering broker fees etc.). Throughout the rest of the project, we will investigate, if this probability can be increased using sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of increase / decrease\n",
    "The later models will attempt to predict the price increase / decrease with regression. As a baseline model, the authors decided to attempt a classification prediction of whether the given headlines' sentiment will trigger an increase / decrease compared to the previous day. This classification will be performed with the Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation (Shuffle = True) ---\n",
      "-- Predictions based on Categorical Sentiment for Price Increase --\n",
      "Accuracy: 0.5883\n",
      "F1-Score: 0.6309\n",
      "-- Predictions based on Categorical Sentiment for Price Decrease --\n",
      "Accuracy: 0.5897\n",
      "F1-Score: 0.5355\n",
      "-- Predictions based on Numerical Score for Price Decrease --\n",
      "Accuracy: 0.5912\n",
      "F1-Score: 0.4271\n",
      "-- Predictions based on Numerical Score for Price Increase --\n",
      "Accuracy: 0.5883\n",
      "F1-Score: 0.6785\n",
      "\n",
      "--- Model Evaluation (Shuffle = False) ---\n",
      "-- Predictions based on Categorical Sentiment for Price Increase --\n",
      "Accuracy: 0.6567\n",
      "F1-Score: 0.6107\n",
      "-- Predictions based on Categorical Sentiment for Price Decrease --\n",
      "Accuracy: 0.6567\n",
      "F1-Score: 0.6930\n",
      "-- Predictions based on Numerical Score for Price Decrease --\n",
      "Accuracy: 0.5997\n",
      "F1-Score: 0.3769\n",
      "-- Predictions based on Numerical Score for Price Increase --\n",
      "Accuracy: 0.5983\n",
      "F1-Score: 0.7044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "#Try with and without shuffling the data\n",
    "for shuffle in [True, False]:\n",
    "    print(f\"--- Model Evaluation (Shuffle = {shuffle}) ---\")\n",
    "    \n",
    "    #Price Increase (Categorical)\n",
    "    X_cat, y_increase = grouped_df[['Positive sentiment', 'Negative sentiment']], grouped_df['Price increase']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cat, y_increase, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    nb_increase_cat = GaussianNB()\n",
    "    y_pred_increase_cat = nb_increase_cat.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    #Use F1-Score for better evaluation of imbalanced classes (average='binary' for 1/0 targets)\n",
    "    increase_f1_categorical = f1_score(y_test, y_pred_increase_cat, average='binary', zero_division=0)\n",
    "    \n",
    "    print(\"-- Predictions based on Categorical Sentiment for Price Increase --\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_increase_cat):.4f}\")\n",
    "    print(f\"F1-Score: {increase_f1_categorical:.4f}\")\n",
    "    \n",
    "    #Price Decrease (Categorical)\n",
    "    X_cat, y_decrease = grouped_df[['Positive sentiment', 'Negative sentiment']], grouped_df['Price decrease']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cat, y_decrease, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    nb_decrease_cat = GaussianNB()\n",
    "    y_pred_decrease_cat = nb_decrease_cat.fit(X_train, y_train).predict(X_test)\n",
    "    decrease_f1_categorical = f1_score(y_test, y_pred_decrease_cat, average='binary', zero_division=0)\n",
    "\n",
    "    print(\"-- Predictions based on Categorical Sentiment for Price Decrease --\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_decrease_cat):.4f}\")\n",
    "    print(f\"F1-Score: {decrease_f1_categorical:.4f}\")\n",
    "    \n",
    "    #Price Decrease (Numerical/Score)\n",
    "    X_num, y_decrease = grouped_df[['Score']], grouped_df['Price decrease']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_num, y_decrease, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    nb_decrease_num = GaussianNB()\n",
    "    y_pred_decrease_num = nb_decrease_num.fit(X_train, y_train).predict(X_test)\n",
    "    decrease_f1_numerical = f1_score(y_test, y_pred_decrease_num, average='binary', zero_division=0)\n",
    "    \n",
    "    print(\"-- Predictions based on Numerical Score for Price Decrease --\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_decrease_num):.4f}\")\n",
    "    print(f\"F1-Score: {decrease_f1_numerical:.4f}\")\n",
    "    \n",
    "    X_num, y_increase = grouped_df[['Score']], grouped_df['Price increase']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_num, y_increase, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    nb_increase_num = GaussianNB()\n",
    "    y_pred_increase_num = nb_increase_num.fit(X_train, y_train).predict(X_test)\n",
    "    increase_f1_numerical = f1_score(y_test, y_pred_increase_num, average='binary', zero_division=0)\n",
    "    \n",
    "    print(\"-- Predictions based on Numerical Score for Price Increase --\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_increase_num):.4f}\")\n",
    "    print(f\"F1-Score: {increase_f1_numerical:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We used the Naïve Bayes classifier to try to predict price increases / decreases based on categorical as well as numerical predictors. As the accuracy suggests, this is a slight improvement over the prior probabilities. Especially when the test data is ordered chronologically, a categorical sentiment seems to be able to predict a price increase and decrease quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Random Forests\n",
    "To supplement the above NB classification approach, we try Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation (Shuffle = True) ---\n",
      "-- Predictions based on Categorical Sentiment for Price Increase --\n",
      "Accuracy: 0.5883\n",
      "F1-Score: 0.6309\n",
      "-- Predictions based on Categorical Sentiment for Price Decrease --\n",
      "Accuracy: 0.5897\n",
      "F1-Score: 0.5355\n",
      "-- Predictions based on Numerical Score for Price Decrease --\n",
      "Accuracy: 0.5926\n",
      "F1-Score: 0.4457\n",
      "-- Predictions based on Numerical Score for Price Increase --\n",
      "Accuracy: 0.5912\n",
      "F1-Score: 0.6764\n",
      "\n",
      "--- Model Evaluation (Shuffle = False) ---\n",
      "-- Predictions based on Categorical Sentiment for Price Increase --\n",
      "Accuracy: 0.6567\n",
      "F1-Score: 0.6107\n",
      "-- Predictions based on Categorical Sentiment for Price Decrease --\n",
      "Accuracy: 0.6567\n",
      "F1-Score: 0.6930\n",
      "-- Predictions based on Numerical Score for Price Decrease --\n",
      "Accuracy: 0.6510\n",
      "F1-Score: 0.5488\n",
      "-- Predictions based on Numerical Score for Price Increase --\n",
      "Accuracy: 0.6510\n",
      "F1-Score: 0.7154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Try with and without shuffling the data\n",
    "for shuffle in [True, False]:\n",
    "    print(f\"--- Model Evaluation (Shuffle = {shuffle}) ---\")\n",
    "    \n",
    "    #Price Increase (Categorical)\n",
    "    X_cat, y_increase = grouped_df[['Positive sentiment', 'Negative sentiment']], grouped_df['Price increase']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cat, y_increase, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    rf_increase_cat = RandomForestClassifier(max_depth=3, n_estimators=1000, random_state=67)\n",
    "    y_pred_increase_cat = rf_increase_cat.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    #Use F1-Score for better evaluation of imbalanced classes (average='binary' for 1/0 targets)\n",
    "    increase_f1_categorical = f1_score(y_test, y_pred_increase_cat, average='binary', zero_division=0)\n",
    "    \n",
    "    print(\"-- Predictions based on Categorical Sentiment for Price Increase --\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_increase_cat):.4f}\")\n",
    "    print(f\"F1-Score: {increase_f1_categorical:.4f}\")\n",
    "    \n",
    "    #Price Decrease (Categorical)\n",
    "    X_cat, y_decrease = grouped_df[['Positive sentiment', 'Negative sentiment']], grouped_df['Price decrease']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cat, y_decrease, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    rf_decrease_cat = RandomForestClassifier(max_depth=3, n_estimators=1000, random_state=67)\n",
    "    y_pred_decrease_cat = rf_decrease_cat.fit(X_train, y_train).predict(X_test)\n",
    "    decrease_f1_categorical = f1_score(y_test, y_pred_decrease_cat, average='binary', zero_division=0)\n",
    "\n",
    "    print(\"-- Predictions based on Categorical Sentiment for Price Decrease --\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_decrease_cat):.4f}\")\n",
    "    print(f\"F1-Score: {decrease_f1_categorical:.4f}\")\n",
    "    \n",
    "    #Price Decrease (Numerical/Score)\n",
    "    X_num, y_decrease = grouped_df[['Score']], grouped_df['Price decrease']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_num, y_decrease, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    rf_decrease_num = RandomForestClassifier(max_depth=3, n_estimators=1000, random_state=67)\n",
    "    y_pred_decrease_num = rf_decrease_num.fit(X_train, y_train).predict(X_test)\n",
    "    decrease_f1_numerical = f1_score(y_test, y_pred_decrease_num, average='binary', zero_division=0)\n",
    "    \n",
    "    print(\"-- Predictions based on Numerical Score for Price Decrease --\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_decrease_num):.4f}\")\n",
    "    print(f\"F1-Score: {decrease_f1_numerical:.4f}\")\n",
    "    \n",
    "    X_num, y_increase = grouped_df[['Score']], grouped_df['Price increase']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_num, y_increase, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    rf_increase_num = RandomForestClassifier(max_depth=3, n_estimators=1000, random_state=67)\n",
    "    y_pred_increase_num = rf_increase_num.fit(X_train, y_train).predict(X_test)\n",
    "    increase_f1_numerical = f1_score(y_test, y_pred_increase_num, average='binary', zero_division=0)\n",
    "    \n",
    "    print(\"-- Predictions based on Numerical Score for Price Increase --\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_increase_num):.4f}\")\n",
    "    print(f\"F1-Score: {increase_f1_numerical:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "The results are very similar to that of NB, while the computation time for NB is slightly faster. This is an argument for sticking to NB.\n",
    "It is strange that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Trying to predict exact stock return (in percent) using different regression methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation (Shuffle = True) ---\n",
      "0.5883190883190883\n",
      "RMSE: 1.2454612716669526\n",
      "--- Model Evaluation (Shuffle = False) ---\n",
      "0.6509971509971509\n",
      "RMSE: 1.062711645210153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "#Try with and without shuffling the data\n",
    "for shuffle in [True, False]:\n",
    "    print(f\"--- Model Evaluation (Shuffle = {shuffle}) ---\")\n",
    "    \n",
    "    #Price Increase (Categorical)\n",
    "    X, y = grouped_df[['Score']].astype(float), grouped_df['Percentage price difference'].astype(float)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=67, shuffle=shuffle)\n",
    "    rf = RandomForestRegressor(max_depth=3, n_estimators=1000, random_state=67)\n",
    "    y_pred_rf = rf.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    rmse = root_mean_squared_error(y_true=y_test, y_pred=y_pred_rf)\n",
    "    # Calculating \"hit rate\" (directional accuracy)\n",
    "    y_test_sign = np.sign(y_test)\n",
    "    y_pred_sign = np.sign(y_pred_rf)\n",
    "    directional_hits = (y_test_sign == y_pred_sign)\n",
    "    directional_accuracy = np.mean(directional_hits)\n",
    "\n",
    "    print(directional_accuracy)\n",
    "    print(f\"RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentimentF24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
